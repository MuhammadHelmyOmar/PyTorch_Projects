{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBhTOnkF288xcoYGqIW1fR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Intro"
      ],
      "metadata": {
        "id": "gMPqHeI6KW28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " - We can define computer vision as the art of teaching a computer to see.\n",
        " - Types of Computer Vision tasks:\n",
        "  - Binary Classification\n",
        "  - Multi-class Classification\n",
        "  - Object Detection\n",
        "  - Panoptic segmentation"
      ],
      "metadata": {
        "id": "bvtGZMCEMpVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CV Libraries in PyTorch"
      ],
      "metadata": {
        "id": "XAI_-BwlJWFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ***torchvision*** contains:\n",
        "  - Datasets\n",
        "  - Model architectures\n",
        "  - Image transformations\n",
        "- ***torchvision.datasets*** contains:\n",
        "  - CV datasets\n",
        "  - series of base classes for making custom datasets\n",
        "- ***torchvision.models*** contains:\n",
        "  - CV model architectures\n",
        "- ***torchvision.transforms*** contains:\n",
        "  - common image transformations (turning images into numbers, or processing or augmenting images)\n",
        "---\n",
        "- ***torch.utils.data.Dataset***: base dataset class for PyTorch\n",
        "- ***torch.utils.data.Dataloader***: creates a Python iterable over a dataset\n",
        "\n",
        "These last two classes aren't only for CV tasks, but they can deal with many different data types."
      ],
      "metadata": {
        "id": "0DYLs3IyJbmL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adJBl6dJKTHG"
      },
      "outputs": [],
      "source": [
        "# import dependencies\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"torch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting a dataset"
      ],
      "metadata": {
        "id": "dWU9Kf1Neowm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- CV dataset: FashionMNIST contains grayscale images of 10 different kinds of clothing.\n",
        "- MNIST: Modified National Institute of Standards and Technology\n",
        "- Multiclass problem\n",
        "- Our task is to identify the type of clothing in an image.\n"
      ],
      "metadata": {
        "id": "5DUdib25eq84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data\n",
        "train_data = datasets.FashionMNIST(\n",
        "    root = \"data\", # root directory\n",
        "    download= True, # download data to the root directory\n",
        "    train= True, # get the training set\n",
        "    transform= ToTensor(), # transform a PIL image to tensor\n",
        "    target_transform= None # if you want to transform the labels too\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    download=True,\n",
        "    train= False,\n",
        "    transform= ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "08xqQcGwuCug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "image, label"
      ],
      "metadata": {
        "id": "2pLqYKfsTaNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Shapes of input and output"
      ],
      "metadata": {
        "id": "lPV_ZuA_k-L5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We have a tensor leading to one lablel.\n"
      ],
      "metadata": {
        "id": "CtN7hy9-lKKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "id": "hgYmAMVhTjqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This corresponds to: [color_channels=1, height=28, width=28]; referred to as CHW\n",
        "- Sometimes images are represented as HWC instead.\n",
        "- N stands for number of images in NCHW or NHWC.\n",
        "- NCHW is the default that PyTorch generally expects.\n",
        "- However, PyTorch states that NHWC is the best practice for better performance when data is large."
      ],
      "metadata": {
        "id": "HSaBRncMlbHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data"
      ],
      "metadata": {
        "id": "bpm3VK_4lmaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data.data), len(train_data.targets)"
      ],
      "metadata": {
        "id": "jlsVVwKM0fId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data.data), len(test_data.targets)"
      ],
      "metadata": {
        "id": "6rr0fFvm0fnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.classes"
      ],
      "metadata": {
        "id": "WDyb2PtmZQ3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Visualization"
      ],
      "metadata": {
        "id": "xCGTqApR5DHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "eyBvLfz_5lGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[1]\n",
        "print(f\"Image shape: {image.shape}\")\n",
        "plt.imshow(image.squeeze())\n",
        "plt.title(label)"
      ],
      "metadata": {
        "id": "IAj01toF5L5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using the grayscale\n",
        "\n",
        "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
        "plt.title(train_data.classes[label])"
      ],
      "metadata": {
        "id": "kpGHmhYO6osD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting more images\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "fig = plt.figure(figsize=(9,9))\n",
        "rows, cols = 4, 4\n",
        "\n",
        "for i in range(1, rows*cols+1):\n",
        "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "    img, label = train_data[random_idx]\n",
        "    fig.add_subplot(rows, cols, i)\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "    plt.title(train_data.classes[label])\n",
        "    plt.axis(False);"
      ],
      "metadata": {
        "id": "ijFChqeSamEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Find patterns based on the pixels values.\n",
        "- 60,000 is considered a small dataset in deep learning.\n",
        "- Goal: classify each image."
      ],
      "metadata": {
        "id": "6zwxRYigsGsz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create DataLoader"
      ],
      "metadata": {
        "id": "iCNiYNnO2Jtp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- DataLoader helps load data into a model for training and inference.\n",
        "- Large dataset are turned into smaller chunks called mini-batches.\n",
        "- This is computationally more efficient while dealing with large datasets.\n",
        "- *batch_size* Hyperparameter: You can use it to adjust the mini-batches size. 32 is a good start and powers of 2 are used often."
      ],
      "metadata": {
        "id": "A1EjGR1a2OFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "nhOAOicSr94L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    dataset=train_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    dataset=test_data,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "4J9JbUswr9pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JVuP9BosFee"
      },
      "outputs": [],
      "source": [
        "print(train_dataloader, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQWjOhMrZ6Lj"
      },
      "outputs": [],
      "source": [
        "print(len(train_dataloader), BATCH_SIZE)\n",
        "print(len(test_dataloader), BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm-kCOBGaPSl"
      },
      "outputs": [],
      "source": [
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8kb1kXljo_n"
      },
      "outputs": [],
      "source": [
        "# Check one sample\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "rand_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "img, label = train_features_batch[rand_idx], train_labels_batch[rand_idx]\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.title(train_data.classes[label])\n",
        "plt.axis(\"off\");\n",
        "print(f\"Image size: {img.shape}\")\n",
        "print(f\"Label: {label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8huySYGLi0ET"
      },
      "source": [
        "# Baseline Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g4uk3a3i7En"
      },
      "source": [
        "- Using *nn.Module* to build the baseline model (simplest imagined model).\n",
        "- Start with the baseline model then add more complications to it subsequently as needed.\n",
        "- *nn.Flaten()* layer is used to compress the dimensions of image data (tensor) into a single long vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJwl7rVMPsjD"
      },
      "outputs": [],
      "source": [
        "# Try nn.Flaten()\n",
        "\n",
        "x = train_features_batch[0]\n",
        "\n",
        "output = nn.Flatten()(x)\n",
        "\n",
        "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Shape before flattening: {output.shape} -> [color_channels, height*width]\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn"
      ],
      "metadata": {
        "id": "qh-ZafQP96EJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTModelV0(nn.Module):\n",
        "    def __init__(self, input_shape:int, hidden_units:int, output_shape:int):\n",
        "        super().__init__()\n",
        "        self.layers_stack= nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features= input_shape, out_features= hidden_units),\n",
        "            nn.Linear(in_features= hidden_units, out_features= output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers_stack(x)"
      ],
      "metadata": {
        "id": "s_KSpiGd-9uG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names= train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "oipg-6_lP_un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate a model\n",
        "torch.manual_seed(42)\n",
        "\n",
        "model_0= FashionMNISTModelV0(\n",
        "    input_shape= 784,\n",
        "    hidden_units= 10,\n",
        "    output_shape= len(class_names)\n",
        ")\n",
        "\n",
        "model_0.to(\"cpu\")"
      ],
      "metadata": {
        "id": "5CiNpSCTPvSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup loss, optimizer, and evaluation metrics"
      ],
      "metadata": {
        "id": "VFlZ-EtMQmhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Summon helper functions."
      ],
      "metadata": {
        "id": "F0A59A4iWej9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "iVGy4c4QQlFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if Path(\"helper_functions.py\").is_file():\n",
        "    print(\"helper_funtions.py already exists.\")\n",
        "else:\n",
        "    print(\"Downloading helper_functions.py\")\n",
        "    request= requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\") # raw github url\n",
        "    with open(\"helper_functions.py\", \"wb\") as f:\n",
        "        f.write(request.content)"
      ],
      "metadata": {
        "id": "Xw8WrXq9WpOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchmetrics"
      ],
      "metadata": {
        "id": "IZUt_EVliUdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchmetrics"
      ],
      "metadata": {
        "id": "vnWUdqVliJq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn= nn.CrossEntropyLoss()\n",
        "optimizer= torch.optim.SGD(params= model_0.parameters(), lr= 0.1)\n",
        "accuracy_fn= torchmetrics.Accuracy(task= \"multiclass\", num_classes= len(class_names)).to(\"cpu\")"
      ],
      "metadata": {
        "id": "48CmCTDKXkoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Measure time of our experiments"
      ],
      "metadata": {
        "id": "BkGbZvWPjDUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can compare time of training on CPU vs GPU."
      ],
      "metadata": {
        "id": "s3hf62PQ9TAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer"
      ],
      "metadata": {
        "id": "nXNPKPbXjCnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_train_time(start: float, end:float, device: torch.device= None):\n",
        "    \"\"\"Prints difference between start and end time.\n",
        "\n",
        "    Args:\n",
        "        start (float): start time of computation.\n",
        "        end (float): end time of computation.\n",
        "        device ([type], optional): device in which the computation is running on (None is the default).\n",
        "    \"\"\"\n",
        "\n",
        "    total_time= end - start\n",
        "    print(f\"Train time on {device}= {total_time:.3f} seconds\")\n",
        "    return total_time"
      ],
      "metadata": {
        "id": "WTQWWgsB9sEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "VoI7-zGRsrbY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Since we are dealing with batches, there will be nested loops.\n",
        "- Loss and evaluation metrics will be calculated per batch instead of the whole dataset. So, at the end, we divide the loss and evaluation metric by the number of batches (normalization)."
      ],
      "metadata": {
        "id": "TAEozyWms_VG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm # Gives progress bar"
      ],
      "metadata": {
        "id": "7mE0rizv-SEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "train_start_time_cpu = timer()\n",
        "\n",
        "EPOCHS= 3 # small number for faster training\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print(f\"Epoch: {epoch}\\n-------\")\n",
        "\n",
        "    ### Training ###\n",
        "\n",
        "    train_loss= 0\n",
        "\n",
        "    for batch, (X,y) in enumerate(train_dataloader):\n",
        "\n",
        "        model_0.train()\n",
        "\n",
        "        train_pred = model_0(X)\n",
        "\n",
        "        curr_loss = loss_fn(train_pred, y)\n",
        "        train_loss += curr_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        curr_loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 400 == 0:\n",
        "            print(f\"Looked at {batch*len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "    # Calculate average train loss per batch\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    ### Testing ###\n",
        "\n",
        "    test_loss, test_acc = 0, 0  # to accumulate tesing loss and accuracy\n",
        "\n",
        "    model_0.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "\n",
        "        for X,y in test_dataloader:\n",
        "\n",
        "            test_pred = model_0(X)\n",
        "\n",
        "            test_loss += loss_fn(test_pred, y)\n",
        "\n",
        "            test_acc += accuracy_fn(\n",
        "                preds = test_pred,\n",
        "                target = y\n",
        "            )\n",
        "\n",
        "        # Calculate avergae test loss per batch\n",
        "        test_loss /= len(test_dataloader)\n",
        "\n",
        "        # Calculate average accuracy per batch\n",
        "        test_acc /= len(test_dataloader)\n",
        "\n",
        "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:0.5f} | Accuracy: {test_acc:0.5f}\")\n",
        "\n",
        "train_end_time_cpu = timer()\n",
        "\n",
        "total_train_time_model_0 = print_train_time(\n",
        "    start = train_start_time_cpu,\n",
        "    end = train_end_time_cpu,\n",
        "    device = str(next(model_0.parameters()).device)\n",
        ")"
      ],
      "metadata": {
        "id": "D1NCg3q00Jzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference and evaluation"
      ],
      "metadata": {
        "id": "EWVLkIUrAyfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create a function that takes:\n",
        "  1. a trained model\n",
        "  2. dataloader\n",
        "  3. loss function\n",
        "  4. accuracy function\n",
        "- The function should use the data in the dataloader and the model to make predictions and then evaluate those predictions with the loss and accuracy functions.\n",
        "- Use the results of this function to compare different models.\n"
      ],
      "metadata": {
        "id": "UrQV2VxyBaFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "def eval_model(model: torch.nn.Module,\n",
        "               data_loader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               accuracy_fn: torchmetrics):\n",
        "\n",
        "    \"\"\"Returns a dictionary contains the model's predictions on the data_loader.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): A PyTorch model capable of making predictions on the data_loader\n",
        "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
        "        loss_fn (torch.nn.Module): A function to calculate the loss for the model's predictions.\n",
        "        accuracy_fn (torchmetrics): A function to calculate accuracy between the model's predictions and the true labels.\n",
        "\n",
        "    Returns:\n",
        "        (dict): The resulting predictions of the model on the dataloader.\n",
        "    \"\"\"\n",
        "\n",
        "    loss, acc = 0, 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for X, y in data_loader:\n",
        "            preds = model(X)\n",
        "            loss += loss_fn(preds, y)\n",
        "            acc += accuracy_fn(\n",
        "                preds = preds,\n",
        "                target = y\n",
        "            )\n",
        "\n",
        "        # Average loss and accuracy per batch\n",
        "        loss /= len(data_loader)\n",
        "        acc /= len(data_loader)\n",
        "\n",
        "    return {\n",
        "        \"model_name\": model.__class__.__name__,\n",
        "        \"model_loss\": loss.item(),\n",
        "        \"model_accuracy\": acc.item()\n",
        "    }"
      ],
      "metadata": {
        "id": "Zy_f-RHGXn_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model_0\n",
        "\n",
        "res = eval_model(\n",
        "    model = model_0,\n",
        "    data_loader = test_dataloader,\n",
        "    loss_fn = loss_fn,\n",
        "    accuracy_fn = accuracy_fn\n",
        ")\n",
        "\n",
        "res"
      ],
      "metadata": {
        "id": "W_blxD-TFd6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non-linear Model"
      ],
      "metadata": {
        "id": "-tZyARB_GPk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turning the code to the device-agnostic mode\n",
        "\n",
        "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "glP3gvZ0dVVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Does our data need non-linearity?\n",
        "  - Linear = straight\n",
        "  - Non-linear = non-straight"
      ],
      "metadata": {
        "id": "fT8ZBMNZsWG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTModelV1(nn.Module):\n",
        "\n",
        "    def __init__(self, input_shape:int, hidden_units:int, output_shape:int):\n",
        "        super().__init__()\n",
        "        self.layers_stack = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x:torch.Tensor):\n",
        "        return self.layers_stack(x)"
      ],
      "metadata": {
        "id": "2fmv4r6ReZcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In ML, it is a good practice to start with a baseline model then experiment changing one thing after another.\n",
        "- This time, we added non-linear functions."
      ],
      "metadata": {
        "id": "xCiWQW6kRZLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate model_1\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "model_1 = FashionMNISTModelV1(\n",
        "    input_shape = 784,\n",
        "    hidden_units = 10,\n",
        "    output_shape = len(class_names)\n",
        ").to(device)\n",
        "\n",
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "id": "WNEMiUqSRLGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup loss, optimizer, and evaluation metrics"
      ],
      "metadata": {
        "id": "uFTbDmcig820"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(\n",
        "    params = model_1.parameters(),\n",
        "    lr = 0.1\n",
        ")\n",
        "\n",
        "accuracy_fn = torchmetrics.Accuracy(\n",
        "    task = \"multiclass\",\n",
        "    num_classes = len(class_names)\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "CLdO2ygPhN_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wrapping up training and testing loops"
      ],
      "metadata": {
        "id": "SV8_T8sb1Irq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create functions that can be repeatedly called:\n",
        "  - train() will take:\n",
        "    - model\n",
        "    - DataLoader\n",
        "    - loss function\n",
        "    - optimizer\n",
        "  - test() will take:\n",
        "    - model\n",
        "    - DataLoader\n",
        "    - loss function\n",
        "    - evaluation function"
      ],
      "metadata": {
        "id": "ad5WqmLP3c0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model: torch.nn.Module,\n",
        "          data_loader: torch.utils.data.DataLoader,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          accuracy_fn: torchmetrics.Metric,\n",
        "          device: torch.device = device):\n",
        "      \"\"\"Loop through your data to train your model\"\"\"\n",
        "\n",
        "      train_loss, train_acc = 0,0\n",
        "      model.to(device)\n",
        "\n",
        "      for batch, (X,y) in enumerate(data_loader):\n",
        "\n",
        "          X.to(device), y.to(device)\n",
        "\n",
        "          preds = model(X)\n",
        "\n",
        "          loss = loss_fn(preds, y)\n",
        "          train_loss += loss\n",
        "          train_acc += accuracy_fn(preds = preds,\n",
        "                                   target = y)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "\n",
        "      # Average loss and accuracy\n",
        "\n",
        "      train_loss /= len(data_loader)\n",
        "      train_acc /= len(data_loader)\n",
        "\n",
        "      print(f\"Train Loss: {train_loss:5.f} | Test Loss: {test_loss:.2f}%\")"
      ],
      "metadata": {
        "id": "Phn0FtoV3b1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "loGu908zj0wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "If you found something wrong, please contact me at: muhammadhelmymmo@gmail.com"
      ],
      "metadata": {
        "id": "0-jJS1UdIMTN"
      }
    }
  ]
}