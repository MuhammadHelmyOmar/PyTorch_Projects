{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN8kJEu2OIu6AruDe6FPceN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadHelmyOmar/PyTorch_Projects/blob/main/custom_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recap"
      ],
      "metadata": {
        "id": "mCcUgmhR43El"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps to solve a machine learning problem:\n",
        "1. Find a dataset\n",
        "2. Turn the dataset into numbers\n",
        "3. Create a model or find a pretrained one to extract the patterns in the data for prediction"
      ],
      "metadata": {
        "id": "oTdoQWu0STDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro"
      ],
      "metadata": {
        "id": "3N6AP54GtHtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Custom Data: a collection of data relating to your problem.\n",
        "- PyTorch provides functions to load in different custom datasets in the **TorchVision**, **TorchText**, **TorchAudio**, and **TorchRec** domain libraries.\n",
        "- If the previous functions are not enough, we can subclass **torch.utils.data.Dataset** and customize it to our needs.\n",
        "- In this notebook, we will not use an in-built PyTorch dataset.\n",
        "- We will load a custom dataset and train a model on it.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZeI28jrvtkIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up environment"
      ],
      "metadata": {
        "id": "Q4xG5UcCJV5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "dbquGT-bJlA2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eb8817b4-09ac-4183-b95e-e6cf43c2fdfc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SKYl1-Xj3UNh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f3e92522-5998-47da-e266-e80acda360a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Using a device-agnostic code is a best practice in DL\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Data"
      ],
      "metadata": {
        "id": "JCnUOmmkTnih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Start with existing data.\n",
        "- We will use a subset of the [Food-101](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/) dataset.\n",
        "- Food-101 splits to:\n",
        "    - 1000 images of 101 different kinds of foods = 101,000 total images\n",
        "    - 750,750 for training and 250,250 for testing\n",
        "- Food-101 is included in PyTorch now."
      ],
      "metadata": {
        "id": "ufL3yhUZT68y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Formatting the custom data"
      ],
      "metadata": {
        "id": "YbcWeywwfwXf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We will start with three food classes: Sushi, Pizza, and Steak."
      ],
      "metadata": {
        "id": "kPSKrmxifz0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Creation"
      ],
      "metadata": {
        "id": "XKKnosGSZHc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torchvision as tv\n",
        "# import pathlib # Setting up data directory\n",
        "\n",
        "# tv.__version__\n",
        "# data_dir = pathlib.Path(\"../data\")"
      ],
      "metadata": {
        "id": "S_WwLuIkgsNH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data = tv.datasets.Food101(root = data_dir,\n",
        "#                          split = \"train\",\n",
        "#                          download = True)\n",
        "\n",
        "# test_data = tv.datasets.Food101(root = data_dir,\n",
        "#                                 split = \"test\",\n",
        "#                                 download = True)"
      ],
      "metadata": {
        "id": "6wopWbj5ow6n"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data, test_data"
      ],
      "metadata": {
        "id": "iBfEyeGRpAlg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class_names = train_data.classes\n",
        "# print(len(class_names))\n",
        "# class_names[:20]"
      ],
      "metadata": {
        "id": "rZq54tf_JYFL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # View a sample image\n",
        "\n",
        "# print(class_names[train_data[1000][1]])\n",
        "# train_data[1000][0]"
      ],
      "metadata": {
        "id": "NdRdlml1Jlhc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subseting appropriate classes"
      ],
      "metadata": {
        "id": "oRWUJ6tvZLRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Copy 10% random images of the specified classes to a separate folders."
      ],
      "metadata": {
        "id": "gFAZ820jZV91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import random"
      ],
      "metadata": {
        "id": "VFEBP_PpY5sF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_path = data_dir / \"food-101\" / \"images\"\n",
        "# target_classes = [\"pizza\", \"steak\", \"sushi\"]\n",
        "\n",
        "# DATA_AMOUNT = 0.1\n",
        "\n",
        "# def get_subset(data_path,\n",
        "#                data_splits = ['train', 'test'],\n",
        "#                target_classes = ['pizza', 'steak', 'sushi'],\n",
        "#                amount = 0.1,\n",
        "#                seed = 42):\n",
        "\n",
        "#     random.seed(seed)\n",
        "#     label_splits = {}\n",
        "\n",
        "#     for data_split in data_splits:\n",
        "\n",
        "#         print(f\"[INFO] Creating {data_split} split..\")\n",
        "\n",
        "#         label_path = data_dir / \"food-101\" / \"meta\" / f\"{data_split}.txt\"\n",
        "#         with open(label_path, 'r') as f:\n",
        "#             labels = [line.strip(\"\\n\") for line in f.readlines() if line.split(\"/\")[0] in target_classes]\n",
        "\n",
        "#         # Extracting a random subset\n",
        "#         n_samples = round(amount * len(labels))\n",
        "#         print(f\"[INFO] Extracting random subset of {n_samples} images for {data_split}..\")\n",
        "#         sample_images = random.sample(labels, k = n_samples)\n",
        "\n",
        "#         # Apply full path\n",
        "#         image_paths = [pathlib.Path(str(data_path / sample_image) + \".jpg\") for sample_image in sample_images]\n",
        "#         label_splits[data_split] = image_paths\n",
        "\n",
        "#     return label_splits"
      ],
      "metadata": {
        "id": "4qLFQoQFvtnu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# label_splits = get_subset(data_path = data_path, amount = DATA_AMOUNT)\n",
        "# label_splits.keys(), label_splits['test'][:14]"
      ],
      "metadata": {
        "id": "zzcbKM9LW9R3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moving images to dedicated folders"
      ],
      "metadata": {
        "id": "KWeNgS22nCK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create target directory path\n",
        "# target_dir_name = f\"../data/pizza_steak_sushi_{str(int(DATA_AMOUNT*100))}_precent\"\n",
        "# print(f\"Creating directory: '{target_dir_name}'\")\n",
        "\n",
        "# # Set up the directories\n",
        "# target_dir = pathlib.Path(target_dir_name)\n",
        "# # Make the directories\n",
        "# target_dir.mkdir(parents = True, exist_ok = True)"
      ],
      "metadata": {
        "id": "PTgOibBFXXHu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(target_dir)"
      ],
      "metadata": {
        "id": "qy7pngqLGQz3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import shutil # Stands for shell utilities and provides some operations on files"
      ],
      "metadata": {
        "id": "Tc1mCz-V6-Vo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for data_split in label_splits.keys():\n",
        "#     for image_path in label_splits[str(data_split)]:\n",
        "#         dest_dir = target_dir / data_split / image_path.parent.stem / image_path.name\n",
        "\n",
        "#         if not dest_dir.parent.is_dir():\n",
        "#             dest_dir.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "#         print(f\"[INFO] Copying {image_path} to {dest_dir}..\")\n",
        "#         shutil.copy2(image_path, dest_dir) # Copyting files while preserving metadata"
      ],
      "metadata": {
        "id": "attYzGFxFhKI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trace directories\n",
        "\n",
        "def trace_dir(dir_path):\n",
        "    \"\"\"\n",
        "    Walk through directories printing its contents.\n",
        "\n",
        "    Args:\n",
        "        dir_path (str): target directory\n",
        "\n",
        "    Returns:\n",
        "        A print out of:\n",
        "            number of subdirectories in dir_path\n",
        "            number of images (files) in each subdirectory\n",
        "            number of each subdirectory\n",
        "    \"\"\"\n",
        "\n",
        "    import os\n",
        "\n",
        "    for subdir_path, subdir_names, file_names in os.walk(dir_path):\n",
        "        print(f\"There are {len(subdir_names)} and {len(file_names)} images in '{subdir_path}'\")"
      ],
      "metadata": {
        "id": "qdaOA09GXGBC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trace_dir(target_dir)"
      ],
      "metadata": {
        "id": "7-tHqVTchTEm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zipping up images folder"
      ],
      "metadata": {
        "id": "JMwPG4xKo_8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# zip_file_name = data_dir / f\"pizza_steak_sushi_{str(int(DATA_AMOUNT*100))}_percent\"\n",
        "\n",
        "# shutil.make_archive(zip_file_name,\n",
        "#                     format = 'zip',\n",
        "#                     root_dir = target_dir)"
      ],
      "metadata": {
        "id": "FOYniYGnn8gy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls -la ../data/"
      ],
      "metadata": {
        "id": "pBzrWMNvvzXY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir -p pizza_sushi_steak\n",
        "# !unzip ../data/pizza_steak_sushi_10_percent.zip -d pizza_sushi_steak"
      ],
      "metadata": {
        "id": "3iAr5tLov6S5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls"
      ],
      "metadata": {
        "id": "KHbYHmsKweQv"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the formatted data directly from github"
      ],
      "metadata": {
        "id": "O083MbXBHHDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests # To deal with HTTP requests from web services and APIs\n",
        "import zipfile\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "J9wmBDYlH0kO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up path to the data\n",
        "data_path = Path(\"data/\")\n",
        "images_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "if images_path.is_dir():\n",
        "    print(f'{images_path} directory exists.')\n",
        "else:\n",
        "    print(f'{images_path} not found.. creating one..')\n",
        "    images_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Download data\n",
        "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "        print(f\"Downloading data..\")\n",
        "        f.write(request.content)\n",
        "\n",
        "    # Unzipping data\n",
        "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", 'r') as zip_ref:\n",
        "        print(f\"Unzipping data..\")\n",
        "        zip_ref.extractall(images_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwWeS1dySgQn",
        "outputId": "456c6b2a-1a1e-4685-e156-f14abcad5257"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi not found.. creating one..\n",
            "Downloading data..\n",
            "Unzipping data..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "rxqRZZTSqboM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Inspect the data and think what you want to do with it.\n",
        "- Image classes exist in seperate directories named after the class name.\n",
        "- Turn this data into a dataset compatible with PyTorch."
      ],
      "metadata": {
        "id": "2zAwl2wvxduw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trace_dir(dir_path = images_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtTx1HJHNZpY",
        "outputId": "39c387d1-72ea-487c-ce9e-7a36142b931d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 and 0 images in 'data/pizza_steak_sushi'\n",
            "There are 3 and 0 images in 'data/pizza_steak_sushi/test'\n",
            "There are 0 and 31 images in 'data/pizza_steak_sushi/test/sushi'\n",
            "There are 0 and 25 images in 'data/pizza_steak_sushi/test/pizza'\n",
            "There are 0 and 19 images in 'data/pizza_steak_sushi/test/steak'\n",
            "There are 3 and 0 images in 'data/pizza_steak_sushi/train'\n",
            "There are 0 and 72 images in 'data/pizza_steak_sushi/train/sushi'\n",
            "There are 0 and 78 images in 'data/pizza_steak_sushi/train/pizza'\n",
            "There are 0 and 75 images in 'data/pizza_steak_sushi/train/steak'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The average total number of images for the test data is 25 images.\n",
        "- The average total number of images for the train data is 75 images."
      ],
      "metadata": {
        "id": "mSu4wCZvN57b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = images_path / 'train'\n",
        "test_dir = images_path / 'test'\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "Tf7G4vyCNfkc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ce34403-edc8-42a1-ea89-fc205a15c178"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('data/pizza_steak_sushi/train'),\n",
              " PosixPath('data/pizza_steak_sushi/test'))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualing Images"
      ],
      "metadata": {
        "id": "9VFMOikun2Qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import PIL\n",
        "\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "7-7Xei1Wn9Hr"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all image paths\n",
        "images_paths = list(images_path.glob(\"*/*/*.jpg\"))\n",
        "\n",
        "random_image_path = random.choice(images_paths)\n",
        "\n",
        "image_class = random_image_path.parent.stem # The name of the directory where the image is stored\n",
        "# print(image_class)\n",
        "\n",
        "img = PIL.Image.open(random_image_path)\n",
        "# print(img)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InT54EGz35_i",
        "outputId": "097b1699-8177-4cbb-8bbe-3a4e720a7863"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512 at 0x7ABD137F7C10>\n"
          ]
        }
      ]
    }
  ]
}