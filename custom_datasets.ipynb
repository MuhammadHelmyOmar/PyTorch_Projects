{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNSct8hIH4AadCv8hgMHDL9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadHelmyOmar/PyTorch_Projects/blob/main/custom_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recap"
      ],
      "metadata": {
        "id": "mCcUgmhR43El"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps to solve a machine learning problem:\n",
        "1. Find a dataset\n",
        "2. Turn the dataset into numbers\n",
        "3. Create a model or find a pretrained one to extract the patterns in the data for prediction"
      ],
      "metadata": {
        "id": "oTdoQWu0STDs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro"
      ],
      "metadata": {
        "id": "3N6AP54GtHtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Custom Data: a collection of data relating to your problem.\n",
        "- PyTorch provides functions to load in different custom datasets in the **TorchVision**, **TorchText**, **TorchAudio**, and **TorchRec** domain libraries.\n",
        "- If the previous functions are not enough, we can subclass **torch.utils.data.Dataset** and customize it to our needs.\n",
        "- In this notebook, we will not use an in-built PyTorch dataset.\n",
        "- We will load a custom dataset and train a model on it.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZeI28jrvtkIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up environment"
      ],
      "metadata": {
        "id": "Q4xG5UcCJV5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "dbquGT-bJlA2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "318b2831-f93a-4620-f529-94bea39c7909"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SKYl1-Xj3UNh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "68ea02ed-1cea-4573-b3d5-583768e2c0fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Using a device-agnostic code is a best practice in DL\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Data"
      ],
      "metadata": {
        "id": "JCnUOmmkTnih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Start with existing data.\n",
        "- We will use a subset of the [Food-101](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/) dataset.\n",
        "- Food-101 splits to:\n",
        "    - 1000 images of 101 different kinds of foods = 101,000 total images\n",
        "    - 750,750 for training and 250,250 for testing\n",
        "- Food-101 is included in PyTorch now."
      ],
      "metadata": {
        "id": "ufL3yhUZT68y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Formatting the custom data"
      ],
      "metadata": {
        "id": "YbcWeywwfwXf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We will start with three food classes: Sushi, Pizza, and Steak."
      ],
      "metadata": {
        "id": "kPSKrmxifz0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Creation"
      ],
      "metadata": {
        "id": "XKKnosGSZHc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision as tv\n",
        "import pathlib # Setting up data directory\n",
        "\n",
        "tv.__version__\n",
        "data_dir = pathlib.Path(\"../data\")"
      ],
      "metadata": {
        "id": "S_WwLuIkgsNH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = tv.datasets.Food101(root = data_dir,\n",
        "                         split = \"train\",\n",
        "                         download = True)\n",
        "\n",
        "test_data = tv.datasets.Food101(root = data_dir,\n",
        "                                split = \"test\",\n",
        "                                download = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wopWbj5ow6n",
        "outputId": "7fc25424-6695-4d90-feb0-947b998076b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.00G/5.00G [02:47<00:00, 29.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data"
      ],
      "metadata": {
        "id": "iBfEyeGRpAlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "print(len(class_names))\n",
        "class_names[:20]"
      ],
      "metadata": {
        "id": "rZq54tf_JYFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View a sample image\n",
        "\n",
        "print(class_names[train_data[1000][1]])\n",
        "train_data[1000][0]"
      ],
      "metadata": {
        "id": "NdRdlml1Jlhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subseting appropriate classes"
      ],
      "metadata": {
        "id": "oRWUJ6tvZLRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Copy 10% random images of the specified classes to a separate folders."
      ],
      "metadata": {
        "id": "gFAZ820jZV91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "VFEBP_PpY5sF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = data_dir / \"food-101\" / \"images\"\n",
        "target_classes = [\"sushi\", \"steak\", \"pizza\"]\n",
        "\n",
        "DATA_AMOUNT = 0.1\n",
        "\n",
        "def get_subset(image_path = data_path,\n",
        "               data_splits = ['train', 'test'],\n",
        "               target_classes = ['pizza', 'steak', 'sushi'],\n",
        "               amount = 0.1,\n",
        "               seed = 42):\n",
        "\n",
        "    random.seed(seed)\n",
        "    label_splits = {}\n",
        "\n",
        "    for data_split in data_splits:\n",
        "\n",
        "        print(f\"[INFO] Creating {data_split} split..\")\n",
        "\n",
        "        label_path = data_dir / \"food-101\" / \"meta\" / f\"{data_split}.txt\"\n",
        "        with open(label_path, 'r') as f:\n",
        "            labels = [line.strip(\"\\n\") for line in f.readlines() if line.split(\"/\")[0] in target_classes]\n",
        "\n",
        "        # Extracting a random subset\n",
        "        n_samples = round(amount * len(labels))\n",
        "        print(f\"[INFO] Extracting random subset of {n_samples} images for {data_split}..\")\n",
        "        sample_images = random.sample(labels, k = n_samples)\n",
        "\n",
        "        # Apply full path\n",
        "        image_paths = [pathlib.Path(str(image_path / sample_image) + \".jpg\") for sample_image in sample_images]\n",
        "        label_splits[data_split] = image_paths\n",
        "\n",
        "    return label_splits"
      ],
      "metadata": {
        "id": "4qLFQoQFvtnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_splits = get_subset(amount = DATA_AMOUNT)\n",
        "label_splits.keys(), label_splits['test'][:14]"
      ],
      "metadata": {
        "id": "zzcbKM9LW9R3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moving images to dedicated folders"
      ],
      "metadata": {
        "id": "KWeNgS22nCK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create target directory path\n",
        "target_dir_name = f\"../data/pizz_sushi_steak_{str(int(DATA_AMOUNT*100))}_precent\"\n",
        "print(f\"Creating directory: '{target_dir_name}'\")\n",
        "\n",
        "# Set up the directories\n",
        "target_dir = pathlib.Path(target_dir_name)\n",
        "# Make the directories\n",
        "target_dir.mkdir(parents = True, exist_ok = True)"
      ],
      "metadata": {
        "id": "PTgOibBFXXHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "id": "Tc1mCz-V6-Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(target_dir)"
      ],
      "metadata": {
        "id": "qy7pngqLGQz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data_split in label_splits.keys():\n",
        "    for image_path in label_splits[str(data_split)]:\n",
        "        print(type(image_path))\n",
        "        print(image_path.parent)\n",
        "        print(image_path.parent.stem)\n",
        "        print(image_path.name)\n",
        "        dest_dir = target_dir / data_split / image_path.parent.stem / image_path.name\n",
        ""
      ],
      "metadata": {
        "id": "attYzGFxFhKI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}